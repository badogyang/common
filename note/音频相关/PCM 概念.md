# PCM 概念



## 一分钟看懂什么是PCM编码

无论是普通音乐爱好者还是耳机发烧友，大家对于常见的音频编码格式多少都会有一点了解，比如MP3、AAC、WAV、[FLAC](https://xiazai.zol.com.cn/detail/44/431698.shtml)、DSD等等。但是，如果突然有人跟你聊到PCM编码格式，可能有些人会有一点懵。那么今天我们就利用大约一分钟的时间，简单快速的了解下什么是PCM编码格式。

  PCM编码（Pulse Code Modulation）即脉冲编码调制，于70年代末发展起来并成为CD和DVD的主要音频调制模式。它的采样频率从44.1kHz到192kHz不等，而在其输入端，需要设置滤波器以限制仅使20Hz～22.05kHz的频率通过，这样即可以覆盖人耳可听的全部频率范围（20Hz～20KHz）。

![img](./img/2c034e14ae9696ea36f268794d0df3a6.png)

 PCM的比特率（采样大小）从14bit发展到16bit、18bit、20bit直到24bit；采样频率从44.1kHz发展到192kHz。因此，PCM约定俗成了无损编码，因为PCM代表了数字音频中最佳的保真水准。然而，因为输入和输出都需要设置滤波器调整频率，所以PCM编码音频的保真度会受到一定限制。PCM的常见文件格式包括WAV、APE与FLAC，它们均为无损音乐文件格式。

　　至于我们最常说的“无损音频”，一般都是指传统CD格式中的16bit/44.1kHz采样率文件，而知所以称其为“无损压缩”，也是因为其包含了20Hz～22.05kHz这个完全覆盖人耳可闻范围的频率而得名。

  几乎所有的有损压缩格式都是从WAV格式压缩转换而来（其内部的编码依然是PCM），而以前很多MP3设备不支持FLAC、APE、AAC等格式是因为它们不支持这些文件的[解压缩](https://xiazai.zol.com.cn/compress_soft_index/compress_page_1.html)，但是至今还没有一款[播放器](https://xiazai.zol.com.cn/mediaplay_soft_index/mediaplay_page_1.html)不支持WAV格式，这是因为WAV格式本身就是PCM码流。



## 蓝牙UART和[PCM](https://so.csdn.net/so/search?q=PCM&spm=1001.2101.3001.7020)接口传输的信号各是什么？（详见如上链接）

### UART:

１、当你通过蓝牙和别人互传文件时，就用ＵＡＲＴ传输。

数据传输如下所示:AP通过uart把数据发送到bt芯片中，通过无线发射出去，对方接收到后传给AP侧处理。

![img](./img/SouthEast.bmp)
２、当你用蓝牙耳机听音乐时，音频信号也由ＵＡＲＴ传输。

 音乐数据通过uart 传送出去，对方耳机接收到后解码播放。如果是录音数据，则同样传回手机端存储。

![img](./img/SouthEast-1685684312587-3.bmp)

### PCM:传输通话时的语音信号。

 ![img](./img/SouthEast-1685684312587-4.png)

 ![img](./img/SouthEast-1685684312587-5.png)

 uart一般是传输文件，也可以传输语音bit流
pcm一般只能传输语音信号

语音通话时数据流：语音数据有3G网络接入，通过PCM传递到蓝牙芯片，蓝牙芯片通过2.4G发射出去，到蓝牙耳机接收，同样[mic](https://so.csdn.net/so/search?q=mic&spm=1001.2101.3001.7020)传回的语言数据做相应处理



## 为什么蓝牙用PCM通道（网络参考）

 纠正个说法，一般手机cpu到蓝牙的通话实时音频传输才都使用pcm，MP3之类的音频走的是urat/usb之类的其他接口。
 真正原因我也不能确定，不过有几个情况可能是原因之一。
 （1）、PCM和IIS的区别在于，PCM一般是固定8k的采样率的单声道音频，最早似乎和固定电话的编码有直接关系，之后所有的话音编码几乎都是在PCM编码基础上再次编码得到的。而IIS则多了一个专门的信号线，采样率也可以配置到较高的频率，如44k；
 （2）、手机通话时候的编码一般都会被解码成8k采样率的PCM码，高了也没有用。因为本来手机通话的话音频段就是300~3400Hz而已，编码也是按8k采样的。某些手机平台并没有IIS接口，相对来说基本上都会有PCM接口；
 （3）、从蓝牙角度讲，蓝牙在制定协议的时候就特意为通话需求制定了一个协议层，专门定义了一种包结构（SCO）用于通话，有很好的实时性。而通过UART传输的包一般为ALC，用分组传输的方式。两种包的编解使用的软硬件都有些区别。sco包支持的基础码率也是8k的pcm.所以一般蓝牙芯片都会有一个PCM接口；
 （4）、还一个原因就是，开始大家这么做了，后来就都这么做了，形成行业规范。

转载：https://blog.csdn.net/xubin341719/article/details/38519555



## I2S接口

I2S(Inter-IC Sound)总线有时候也写作 IIS，I2S 是飞利浦公司提出的一种用于数字音频设备之间进行音频数据传输的总线。和 I2C、SPI 这些常见的通信协议一样，I2S 总线用于主控制器和音频 CODEC 芯片之间传输音频数据。因此，要想使用 I2S 协议，主控制器和音频 CODEC 都得支持 I2S 协议。

I2S 接口需要 3 根信号线(如果需要实现收和发，那么就要 4根信号线，收和发分别使用一根信号线)：
SCK：串行时钟信号，也叫做位时钟(BCLK)，音频数据的每一位数据都对应一个 SCK，立体声都是双声道的，因此 SCK=2×采样率×采样位数。比如采样率为 44.1KHz、16 位的立体声音频，那么 SCK=2×44100×16=1411200Hz=1.4112MHz。
WS：字段(声道)选择信号，也叫做 LRCK，也叫做帧时钟，用于切换左右声道数据，WS 为 “1表示正在传输左声道的数据，WS 为“0”表示正在传输右声道的数据。WS 的频率等于采样率，比如采样率为 44.1KHz 的音频，WS=44.1KHz。
SD：串行数据信号，也就是我们实际的音频数据，如果要同时实现放音和录音，那么就需要 2 根数据线，比如 WM8960 的 ADCDAT 和 DACDAT，就是分别用于录音和放音。不管音频数据是多少位的，数据的最高位都是最先传输的。数据的最高位总是出现在一帧开始后(LRCK变化)的第 2 个 SCK 脉冲处。

有时候为了使音频 CODEC 芯片与主控制器之间能够更好的同步，会引入另外一个叫做 MCLK 的信号，也叫做主时钟或系统时钟，一般是采样率的 256 倍或 384 倍。

一帧立体声音频时序图：

![img](./img/c342cb79c2e14a86bafdf1abd0b7f43b.png)

随着技术的发展，在统一的 I2S 接口下，出现了不同的数据格式，根据 DATA 数据相对于 LRCK 和 SCLK 位置的不同，出现了 LeftJustified(左对齐)和 RightJustified(右对齐)两种格式，这两种格式的时序图如图所示：

![img](./img/47d8448ea6e54feabe8d9d7bfd983469.png)

左对齐：数据的MSB在LRCLK边沿起第一个BCLK上升沿，用的比较少。
右对齐：数据的LSB靠左LRCLK的上升沿，Sony使用这种格式。

在I2S总线上，I2S传输的是PCM编码后的音频数据，，只能同时存在一个主设备和发送设备。主设备可以是发送设备，也可以是接收设备，或是协调发送设备和接收设备的其它控制设备。在I2S系统中，提供时钟（BCLK和LRCLK）的设备为主设备。





## 3、PCM接口

针对不同的数字音频子系统，出现了几种微处理器或DSP与音频器件间用于数字转换的接口。

最简单的音频接口是PCM（脉冲编码调制）接口，该接口由时钟脉 冲（BCLK）、帧同步信号（FS）及接收数据（DR）和发送数据（DX）组成。在FS信号的上升沿，数据传输从MSB（Most Significant Bit）字开始，FS频率等于采样率。FS信号之后开始数据字的传输，单个的数据位按顺序进行传输，1个时钟周期传输1个数据字。发送MSB时，信号的等 级首先降到最低，以避免在不同终端的接口使用不同的数据方案时造成MSB的丢失。

PCM接口包括四根信号：

- PCM_CLK ：数据时钟信号

- PCM_SYNC ：帧同步时钟信号
- PCM_IN ：接收数据信号
- PCM_OUT ：发送数据信号



和I2S接口差不多，PCM接口是4根信号线，通常用于AP处理器和通信MODEM之间传输语音数据（就是双向打电话的数据）。
